4(a) Write a Python NLTK program to perform Stemming and Lemmatization on set of tokens.

 PorterStemmer(), 

SnowballStemmer(), 

LancasterStemmer(), 

RegexpStemmer()
WordNetLemmatizer() ,lemmatizer.lemmatize()


import nltk
from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, RegexpStemmer
from nltk.stem import WordNetLemmatizer

# Set of tokens
tokens = ['running', 'jumps', 'jumping', 'ran', 'better', 'best', 'wolves', 'dogs']

# Porter Stemmer
porter = PorterStemmer()
stemmed_porter = [porter.stem(token) for token in tokens]
print("Porter Stemmer:")
print(stemmed_porter)

# Snowball Stemmer
snowball = SnowballStemmer('english')
stemmed_snowball = [snowball.stem(token) for token in tokens]
print("\nSnowball Stemmer:")
print(stemmed_snowball)

# Lancaster Stemmer
lancaster = LancasterStemmer()
stemmed_lancaster = [lancaster.stem(token) for token in tokens]
print("\nLancaster Stemmer:")
print(stemmed_lancaster)

# Regexp Stemmer
regexp = RegexpStemmer('ing$|s$|ed$', min=4)
stemmed_regexp = [regexp.stem(token) for token in tokens]
print("\nRegexp Stemmer:")
print(stemmed_regexp)

# WordNet Lemmatizer
lemmatizer = WordNetLemmatizer()
lemmatized = [lemmatizer.lemmatize(token) for token in tokens]
print("\nWordNet Lemmatizer:")
print(lemmatized)
