word embeddings Document Term Matrix for different chapters of brown corpus.

(Take any text file from brown corpus and represent it in document term matrix form)


import nltk
from nltk.corpus import brown
from sklearn.feature_extraction.text import CountVectorizer

# Load the Brown Corpus
nltk.download('brown')
corpus = brown.fileids()

# Select chapters from the corpus
chapters = ['ca01', 'ca02', 'ca03']  # Example chapters

# Initialize a list to store the chapter texts
chapter_texts = []

# Iterate over chapters and extract the text
for chapter in chapters:
    text = ' '.join(brown.words(chapter))
    chapter_texts.append(text)

# Create a CountVectorizer using word embeddings
vectorizer = CountVectorizer()

# Fit and transform the chapter texts to create the document-term matrix
dtm = vectorizer.fit_transform(chapter_texts)

# Get the feature names (words) from the vectorizer
feature_names = vectorizer.get_feature_names()

# Print the document-term matrix
print("Document-Term Matrix:")
print(dtm.toarray())

# Print the feature names (words)
print("\nFeature Names (Words):")
print(feature_names)
